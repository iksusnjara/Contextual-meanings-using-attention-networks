{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/train_shortened.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all columns except question title, question, answer and ratings\n",
    "\n",
    "cols = ['question_title', 'question_body', 'answer']\n",
    "for i in data.columns[12:]:\n",
    "    cols.append(i)\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "\n",
    "## Lowercasing and removing special characters\n",
    "\n",
    "All special chars, except .?! are removed to keep clean text data. Stop, quetion mark and exclamation mark are kept, and will gain separate tokens, as end of sentence markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = data['question_title'].values.copy()\n",
    "questions = data['question_body'].values.copy()\n",
    "answers = data['answer'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessor(texts):\n",
    "\n",
    "    # final list\n",
    "    texts_prep = []\n",
    "    # chars to remove from text\n",
    "    filters =['\\'', '\\\"', '$', '%' ,'&', '(', ')', '*', ',', '+', '-', '/',':',';','<','=','>'\n",
    "              ,'[',']','^','_','`','{','|','}','~','\\t','\\n', '@', '\\\\']\n",
    "\n",
    "    # cleaning whitespace: only one (' ') remains\n",
    "    whitespace_cleaner = re.compile(r'\\s+')\n",
    "    for i in range(len(texts)):\n",
    "        texts[i] = whitespace_cleaner.sub(' ', texts[i]).strip()\n",
    "\n",
    "    # for each text\n",
    "    for text in texts:\n",
    "        # split it by whitespace\n",
    "        split = text.split(' ')\n",
    "        # list to save preprocessed text\n",
    "        to_add = []\n",
    "        # going word by word\n",
    "        for word in split:\n",
    "            proc = []\n",
    "            # making list of valid words, removing urls\n",
    "            if word.isascii() and word.startswith('http') == False:\n",
    "                x = list(word)\n",
    "                # going char by char\n",
    "                for i in x:\n",
    "                    # if char is not to be filtered out, keep it, else add whitespace instead of it\n",
    "                    if i not in filters:\n",
    "                        # if .?!, add whitespace to it, to keep it as separate token\n",
    "                        if i == '?' or i == '.' or i == '!':\n",
    "                            proc.append(' ' + i)\n",
    "                        else:\n",
    "                            proc.append(i)\n",
    "                    else:\n",
    "                        proc.append(' ')\n",
    "                    if '' in proc:\n",
    "                        proc.remove('')\n",
    "                # apending word to to_add list, which contains its whole text\n",
    "                to_add.append(''.join(proc).lower())\n",
    "                    \n",
    "        # apending list of words back to all texts list\n",
    "        texts_prep.append(' '.join(to_add).strip())\n",
    "        \n",
    "    # cleaning whitespace again: only one (' ') remains\n",
    "    whitespace_cleaner = re.compile(r'\\s+')\n",
    "    for i in range(len(texts_prep)):\n",
    "        texts_prep[i] = whitespace_cleaner.sub(' ', texts_prep[i]).strip()\n",
    "        \n",
    "    return texts_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = text_preprocessor(question_titles)\n",
    "questions = text_preprocessor(questions)\n",
    "answers = text_preprocessor(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:    Not only can you, you have to. You never roll a &ldquo;Craft check&rdquo; or &ldquo;Perform check,&rdquo; those skills don&rsquo;t exist. Rather, they are categories of skills, like &ldquo;Craft (basketweaving)&rdquo; or &ldquo;Perform (underwater basketweaving).&rdquo; That&rsquo;s still true even if you have no ranks, and it&rsquo;s relevant for things like feats or instruments, which may need to be compatible with the chosen Craft or Perform skill.\n",
      "\n",
      "Craft and Perform may be used without ranks, so if you have high Intelligence or high Charisma, and/or other bonuses to those skills, you could even be good at them without any training (e.g. ranks). It&rsquo;d be hard to keep up with someone who is actually training it, though.\n",
      "\n",
      "Profession&rsquo;s much the same, but unless you are trained, you cannot roll the specific Profession skill at all (instead, you just get a flat 1 sp/day as unskilled labor). So having ranks in Profession (woven-basket critic) doesn&rsquo;t let you roll for Profession (woven-basket recycler) checks; they are separate skills, and you have no ranks in the latter. But you still have to make the distinction between the two.\n",
      " \n",
      " PROCESSED:    not only can you you have to . you never roll a ldquo craft check rdquo or ldquo perform check rdquo those skills don rsquo t exist . rather they are categories of skills like ldquo craft basketweaving rdquo or ldquo perform underwater basketweaving . rdquo that rsquo s still true even if you have no ranks and it rsquo s relevant for things like feats or instruments which may need to be compatible with the chosen craft or perform skill . craft and perform may be used without ranks so if you have high intelligence or high charisma and or other bonuses to those skills you could even be good at them without any training e .g . ranks . it rsquo d be hard to keep up with someone who is actually training it though . profession rsquo s much the same but unless you are trained you cannot roll the specific profession skill at all instead you just get a flat 1 sp day as unskilled labor . so having ranks in profession woven basket critic doesn rsquo t let you roll for profession woven basket recycler checks they are separate skills and you have no ranks in the latter . but you still have to make the distinction between the two . \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    Not to strong (because don't chech second string but it easy to settle) and can be is not posix compilant but very simple:\n",
      "\n",
      "sed '/^Some text/{:1;/another thing$/!{N;b 1}\n",
      "     s/.*/this is completely\\ndifferent text/g}' input.txt\n",
      "\n",
      "\n",
      "First command add lines from Some text until have met another thing then second line change it to other text.\n",
      "\n",
      "NOTE Limitation is that Some text should always be followed by another thing.\n",
      " \n",
      " PROCESSED:    not to strong because don t chech second string but it easy to settle and can be is not posix compilant but very simple sed some text 1 another thing ! n b 1 s . this is completely ndifferent text g input .txt first command add lines from some text until have met another thing then second line change it to other text . note limitation is that some text should always be followed by another thing . \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    Note that in a directed set every finite subset has an upper bound. If the directed set itself is finite, then it must have a maximum (why?). Therefore the limit of such net is the element associated with the maximum index.\n",
      "\n",
      "Convergence is trivial in that case.\n",
      " \n",
      " PROCESSED:    note that in a directed set every finite subset has an upper bound . if the directed set itself is finite then it must have a maximum why ? . therefore the limit of such net is the element associated with the maximum index . convergence is trivial in that case . \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    It really depends on the music. I don't think there are any rhythmic permutations of 2/4 time that we could definitively say should not be slurred. Emphasis could be anywhere in a measure depending on where the composer has decided to phrase. Perhaps one thing you might try doing is finding repeated material and play it differently (either with dynamics or articulation) the second time around.\n",
      "\n",
      "However, you do want to stay true to the style of that historical music. Have you listened to professional recordings that use period instruments and performance practice? You may find that each note in that passage is meant to be articulated, but at the same time there may be a few things you can do to vary that articulation; perhaps by experimenting with different tongue positions and note lengths.\n",
      " \n",
      " PROCESSED:    it really depends on the music . i don t think there are any rhythmic permutations of 2 4 time that we could definitively say should not be slurred . emphasis could be anywhere in a measure depending on where the composer has decided to phrase . perhaps one thing you might try doing is finding repeated material and play it differently either with dynamics or articulation the second time around . however you do want to stay true to the style of that historical music . have you listened to professional recordings that use period instruments and performance practice ? you may find that each note in that passage is meant to be articulated but at the same time there may be a few things you can do to vary that articulation perhaps by experimenting with different tongue positions and note lengths . \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    I have the same problem at the moment... I am not too sure what causes it but I do notice the pain happens when I power up hills whilst seated in a high gears. I do a 3.5 mile commute everyday with a couple of short uphill bursts. I might try and use a lower gear in a standing position. I am also experimenting with different seats and seat post height, I think since I have lowered the seat height the pain is not as bad. I have also experienced some knee pain\n",
      " \n",
      " PROCESSED:    i have the same problem at the moment . . . i am not too sure what causes it but i do notice the pain happens when i power up hills whilst seated in a high gears . i do a 3 .5 mile commute everyday with a couple of short uphill bursts . i might try and use a lower gear in a standing position . i am also experimenting with different seats and seat post height i think since i have lowered the seat height the pain is not as bad . i have also experienced some knee pain \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing few answers before and after preprocessing\n",
    "\n",
    "rdm = np.random.randint(0,len(answers), 5)\n",
    "\n",
    "for i in rdm:\n",
    "    print('ORIGINAL:   ', data.iloc[i]['answer'], '\\n', 'PROCESSED:   ', answers[i], '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging all words in tweets, and keeping tags only for nouns, verbs, adjectives and adverbs\n",
    "\n",
    "def pos_tagger(texts):\n",
    "\n",
    "    # procesed array-to-be\n",
    "    texts_tagged = []\n",
    "\n",
    "    for text in texts:\n",
    "        # here each text is added after tagging\n",
    "        tagged_final = []\n",
    "        # splitting by whitespace and tagging\n",
    "        split = text.split(' ')\n",
    "        split = np.array(split)\n",
    "        # some '' are stil left in list, cleaning them with numpy where\n",
    "        where = np.where(split == '')\n",
    "        split = np.delete(split, where)\n",
    "        tagged = nltk.pos_tag(split)\n",
    "        # keeping only tags for nouns, verbs, adjectives and adverbs\n",
    "        for item in tagged:\n",
    "            if item[1].startswith('N'):\n",
    "                tagged_final.append((item[0],'n'))\n",
    "            elif item[1].startswith('V'):\n",
    "                tagged_final.append((item[0],'v'))\n",
    "            elif item[1].startswith('J'):\n",
    "                tagged_final.append((item[0],'a'))\n",
    "            elif item[1].startswith('R'):\n",
    "                tagged_final.append((item[0],'r'))\n",
    "            else:\n",
    "                tagged_final.append((item[0], None))\n",
    "        # adding back to final list\n",
    "        texts_tagged.append(tagged_final)\n",
    "    \n",
    "    return np.array(texts_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = pos_tagger(question_titles)\n",
    "questions = pos_tagger(questions)\n",
    "answers = pos_tagger(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', None),\n",
       " ('am', 'v'),\n",
       " ('i', 'a'),\n",
       " ('losing', 'n'),\n",
       " ('when', None),\n",
       " ('using', 'v'),\n",
       " ('extension', 'n'),\n",
       " ('tubes', 'n'),\n",
       " ('instead', 'r'),\n",
       " ('of', None),\n",
       " ('a', None),\n",
       " ('macro', 'n'),\n",
       " ('lens', 'n'),\n",
       " ('?', None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(texts):\n",
    "    \n",
    "    # using wordnet lemmatizer\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lem = WordNetLemmatizer()\n",
    "    \n",
    "    # lemmatized texts list to be\n",
    "    texts_lemmed = []\n",
    "    # going text by text, if word has valid tag (not None), lemmatize it\n",
    "    for text in texts:\n",
    "        to_add = []\n",
    "        for i,j in text:\n",
    "            if j == None:\n",
    "                to_add.append(i)\n",
    "            else:\n",
    "                to_add.append(lem.lemmatize(i, pos = j))\n",
    "        texts_lemmed.append(' '.join(to_add))\n",
    "    \n",
    "    return np.array(texts_lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = lemmatize(question_titles)\n",
    "questions = lemmatize(questions)\n",
    "answers = lemmatize(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['what be i losing when use extension tube instead of a macro lens ?',\n",
       "       'what be the distinction between a city and a sprawl metroplex . . . between downtown and a commercial district ?',\n",
       "       'maximum protusion length for through hole component pin', ...,\n",
       "       'suppress file truncate message when use tail',\n",
       "       'when should a supervisor be a co author ?',\n",
       "       'why be there so many different type of screw phillps flat hex star etc ?'],\n",
       "      dtype='<U140')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking all texts together\n",
    "\n",
    "all_texts = np.hstack((question_titles, questions, answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1741106"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing how many unique words there are\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for i in all_texts:\n",
    "    x = i.split(' ')\n",
    "    for j in x:\n",
    "        all_words.append(j)\n",
    "        \n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44123"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique words\n",
    "\n",
    "len(list(set(all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44123"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only words which show up 10 or more times in tweets as tokens, discarding rest\n",
    "\n",
    "tokens = {k:v for k,v in freq_dist.items() if v >= 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8276"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting tokenizer on all texts\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tok = Tokenizer(num_words = 8277, filters = '')\n",
    "\n",
    "tok.fit_on_texts(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = tok.texts_to_sequences(question_titles)\n",
    "questions = tok.texts_to_sequences(questions)\n",
    "answers = tok.texts_to_sequences(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max len\n",
    "\n",
    "max_len = []\n",
    "\n",
    "for i in question_titles:\n",
    "    max_len.append(len(i))\n",
    "for i in questions:\n",
    "    max_len.append(len(i))\n",
    "for i in answers:\n",
    "    max_len.append(len(i))\n",
    "    \n",
    "max(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18237.000000\n",
       "mean        90.573340\n",
       "std        107.365434\n",
       "min          0.000000\n",
       "5%           5.000000\n",
       "25%         12.000000\n",
       "50%         55.000000\n",
       "75%        126.000000\n",
       "95%        310.000000\n",
       "99%        512.000000\n",
       "max        887.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(max_len).describe(percentiles=[0.05,0.25,0.5,0.75,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAST0lEQVR4nO3df6xc5X3n8fenOCHbdBObYJDXttZEsdrQSAnoCpymWnVD1xgS1fwRKqKquNSS/2F301WlLuxWQs0PiUirEiJt0VrgrhNlCyxNF4tGYS2HaLV/hHAJlAQcyg2h+NYU39SGbhs1W9Jv/5jHZLDn3jsXrufi+7xf0mjO+Z5nZs45HD7z3GeeGaeqkCT14adWegckSZNj6EtSRwx9SeqIoS9JHTH0Jakja1Z6BxZy/vnn15YtW1Z6NyTprPLoo4/+oKrWj9r2pg79LVu2MD09vdK7IUlnlSR/Md82h3ckqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjY30jN8la4E7gfUABvwk8DdwDbAGeA361qk4kCXA7cDXwQ+A3qupb7Xl2Ab/bnvbTVbV/2Y5khC03/enI+nO3fuRMvqwkvWmN29O/HfhqVf0c8H7gMHATcKiqtgKH2jrAVcDWdtsD3AGQ5DzgFuBy4DLgliTrluk4JEljWDT0k7wD+FfAXQBV9f+r6iVgJ3Cyp74fuKYt7wS+UAPfANYm2QBcCRysquNVdQI4COxY1qORJC1onJ7+u4E54A+TPJbkziRvBy6sqhcA2v0Frf1G4MjQ42dbbb76ayTZk2Q6yfTc3NySD0iSNL9xQn8NcClwR1VdAvwdPxnKGSUjarVA/bWFqr1VNVVVU+vXj/xlUEnS6zRO6M8Cs1X1cFu/j8GbwItt2IZ2f2yo/eahx28Cji5QlyRNyKKhX1V/BRxJ8rOtdAXwFHAA2NVqu4D72/IB4PoMbANebsM/DwLbk6xrH+BubzVJ0oSM+4+o/DvgS0neCjwL3MDgDePeJLuB54FrW9uvMJiuOcNgyuYNAFV1PMmngEdau09W1fFlOQpJ0ljGCv2qehyYGrHpihFtC7hxnufZB+xbyg5KkpaP38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6MFfpJnkvy7SSPJ5lutfOSHEzyTLtf1+pJ8vkkM0meSHLp0PPsau2fSbLrzBySJGk+S+np/+uq+kBVTbX1m4BDVbUVONTWAa4CtrbbHuAOGLxJALcAlwOXAbecfKOQJE3GGxne2Qnsb8v7gWuG6l+ogW8Aa5NsAK4EDlbV8ao6ARwEdryB15ckLdG4oV/A/07yaJI9rXZhVb0A0O4vaPWNwJGhx8622nz110iyJ8l0kum5ubnxj0SStKg1Y7b7UFUdTXIBcDDJdxdomxG1WqD+2kLVXmAvwNTU1GnbJUmv31g9/ao62u6PAX/CYEz+xTZsQ7s/1prPApuHHr4JOLpAXZI0IYuGfpK3J/nnJ5eB7cB3gAPAyRk4u4D72/IB4Po2i2cb8HIb/nkQ2J5kXfsAd3urSZImZJzhnQuBP0lysv3/qKqvJnkEuDfJbuB54NrW/ivA1cAM8EPgBoCqOp7kU8Ajrd0nq+r4sh2JJGlRi4Z+VT0LvH9E/a+BK0bUC7hxnufaB+xb+m5KkpaD38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6MHfpJzknyWJIH2vpFSR5O8kySe5K8tdXPbeszbfuWoee4udWfTnLlch+MJGlhS+npfwI4PLT+WeC2qtoKnAB2t/pu4ERVvQe4rbUjycXAdcDPAzuAP0hyzhvbfUnSUowV+kk2AR8B7mzrAT4M3Nea7Aeuacs72zpt+xWt/U7g7qr6UVV9H5gBLluOg5AkjWfcnv7ngN8B/rGtvwt4qapeaeuzwMa2vBE4AtC2v9zav1of8ZhXJdmTZDrJ9Nzc3BIORZK0mEVDP8lHgWNV9ehweUTTWmTbQo/5SaFqb1VNVdXU+vXrF9s9SdISrBmjzYeAX0lyNfA24B0Mev5rk6xpvflNwNHWfhbYDMwmWQO8Ezg+VD9p+DGSpAlYtKdfVTdX1aaq2sLgg9ivVdWvAQ8BH2vNdgH3t+UDbZ22/WtVVa1+XZvdcxGwFfjmsh2JJGlR4/T05/MfgbuTfBp4DLir1e8CvphkhkEP/zqAqnoyyb3AU8ArwI1V9eM38PqSpCVaUuhX1deBr7flZxkx+6aq/h64dp7Hfwb4zFJ3UpK0PPxGriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZNHQT/K2JN9M8mdJnkzye61+UZKHkzyT5J4kb231c9v6TNu+Zei5bm71p5NceaYOSpI02jg9/R8BH66q9wMfAHYk2QZ8FritqrYCJ4Ddrf1u4ERVvQe4rbUjycXAdcDPAzuAP0hyznIejCRpYYuGfg38bVt9S7sV8GHgvlbfD1zTlne2ddr2K5Kk1e+uqh9V1feBGeCyZTkKSdJYxhrTT3JOkseBY8BB4HvAS1X1SmsyC2xsyxuBIwBt+8vAu4brIx4z/Fp7kkwnmZ6bm1v6EUmS5jVW6FfVj6vqA8AmBr3z945q1u4zz7b56qe+1t6qmqqqqfXr14+ze5KkMS1p9k5VvQR8HdgGrE2ypm3aBBxty7PAZoC2/Z3A8eH6iMdIkiZgnNk765Osbcv/DPhl4DDwEPCx1mwXcH9bPtDWadu/VlXV6te12T0XAVuBby7XgUiSFrdm8SZsAPa3mTY/BdxbVQ8keQq4O8mngceAu1r7u4AvJplh0MO/DqCqnkxyL/AU8ApwY1X9eHkPR5K0kEVDv6qeAC4ZUX+WEbNvqurvgWvnea7PAJ9Z+m5KkpaD38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4sGvpJNid5KMnhJE8m+USrn5fkYJJn2v26Vk+SzyeZSfJEkkuHnmtXa/9Mkl1n7rAkSaOM09N/BfjtqnovsA24McnFwE3AoaraChxq6wBXAVvbbQ9wBwzeJIBbgMuBy4BbTr5RSJImY9HQr6oXqupbbfn/AYeBjcBOYH9rth+4pi3vBL5QA98A1ibZAFwJHKyq41V1AjgI7FjWo5EkLWhJY/pJtgCXAA8DF1bVCzB4YwAuaM02AkeGHjbbavPVT32NPUmmk0zPzc0tZfckSYsYO/ST/Azwx8BvVdXfLNR0RK0WqL+2ULW3qqaqamr9+vXj7p4kaQxjhX6StzAI/C9V1Zdb+cU2bEO7P9bqs8DmoYdvAo4uUJckTcg4s3cC3AUcrqrfH9p0ADg5A2cXcP9Q/fo2i2cb8HIb/nkQ2J5kXfsAd3urSZImZM0YbT4E/Drw7SSPt9p/Am4F7k2yG3geuLZt+wpwNTAD/BC4AaCqjif5FPBIa/fJqjq+LEchSRrLoqFfVf+X0ePxAFeMaF/AjfM81z5g31J2UJK0fPxGriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6Ms6vbHZjy01/OrL+3K0fmfCeSNKZYU9fkjrSZU9/vh69JK129vQlqSOGviR1pMvhnaVa6nCQH/xKerOypy9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcWnaefZB/wUeBYVb2v1c4D7gG2AM8Bv1pVJ5IEuB24Gvgh8BtV9a32mF3A77an/XRV7V/eQ3nz8IfbJL1ZjdPT/+/AjlNqNwGHqmorcKitA1wFbG23PcAd8OqbxC3A5cBlwC1J1r3RnZckLc2ioV9V/wc4fkp5J3Cyp74fuGao/oUa+AawNskG4ErgYFUdr6oTwEFOfyORJJ1hr3dM/8KqegGg3V/Q6huBI0PtZlttvvppkuxJMp1kem5u7nXuniRplOX+IDcjarVA/fRi1d6qmqqqqfXr1y/rzklS715v6L/Yhm1o98dafRbYPNRuE3B0gbokaYJeb+gfAHa15V3A/UP16zOwDXi5Df88CGxPsq59gLu91SRJEzTOlM0/An4JOD/JLINZOLcC9ybZDTwPXNuaf4XBdM0ZBlM2bwCoquNJPgU80tp9sqpO/XB41XMqp6SVtmjoV9XH59l0xYi2Bdw4z/PsA/Ytae8kScvKb+RKUkcMfUnqiKEvSR0x9CWpI/7D6G8CzuqRNCn29CWpI4a+JHXE4Z03MYd9JC03e/qS1BFDX5I6YuhLUkcc0z8LOdYv6fUy9FeR+d4MwDcESQMO70hSRwx9SeqIoS9JHXFMvxN++CsJ7OlLUlfs6XfOvwCkvtjTl6SO2NPXSAvN+R/Fvwyks4M9fUnqiKEvSR1xeEfLYqnDQfNxmEg6swx9vak4m0g6syYe+kl2ALcD5wB3VtWtk94HnX2W+mZwNr15+KG5JilVNbkXS84B/hz4N8As8Ajw8ap6alT7qampmp6eft2vt1xDDtJSLPWN6Ey/rvqT5NGqmhq1bdI9/cuAmap6FiDJ3cBOYGToS2ejlepsLNdfQws9Rme/SYf+RuDI0PoscPlwgyR7gD1t9W+TPP0GXu984Adv4PGrjefjdKv+nOSzS2p+PvCDJT5mtTsbr5F/Od+GSYd+RtReM75UVXuBvcvyYsn0fH/i9MjzcTrPyWt5Pk632s7JpOfpzwKbh9Y3AUcnvA+S1K1Jh/4jwNYkFyV5K3AdcGDC+yBJ3Zro8E5VvZLk3wIPMpiyua+qnjyDL7ksw0SriOfjdJ6T1/J8nG5VnZOJTtmUJK0sf3tHkjpi6EtSR1Zl6CfZkeTpJDNJblrp/ZmEJJuTPJTkcJInk3yi1c9LcjDJM+1+XasnyefbOXoiyaUrewRnTpJzkjyW5IG2flGSh9s5uadNKiDJuW19pm3fspL7faYkWZvkviTfbdfLB3u+TpL8h/b/zHeS/FGSt63ma2TVhX77qYf/ClwFXAx8PMnFK7tXE/EK8NtV9V5gG3BjO+6bgENVtRU41NZhcH62ttse4I7J7/LEfAI4PLT+WeC2dk5OALtbfTdwoqreA9zW2q1GtwNfraqfA97P4Nx0eZ0k2Qj8e2Cqqt7HYILJdazma6SqVtUN+CDw4ND6zcDNK71fK3Ae7mfwG0dPAxtabQPwdFv+bwx+9+hk+1fbraYbg++CHAI+DDzA4AuCPwDWnHq9MJhV9sG2vKa1y0ofwzKfj3cA3z/1uHq9TvjJrwSc1/6bPwBcuZqvkVXX02f0Tz1sXKF9WRHtT85LgIeBC6vqBYB2f0Fr1st5+hzwO8A/tvV3AS9V1Sttffi4Xz0nbfvLrf1q8m5gDvjDNuR1Z5K30+l1UlV/CfwX4HngBQb/zR9lFV8jqzH0F/2ph9Usyc8Afwz8VlX9zUJNR9RW1XlK8lHgWFU9Olwe0bTG2LZarAEuBe6oqkuAv+MnQzmjrOpz0j672AlcBPwL4O0MhrROtWqukdUY+t3+1EOStzAI/C9V1Zdb+cUkG9r2DcCxVu/hPH0I+JUkzwF3Mxji+RywNsnJLyYOH/er56RtfydwfJI7PAGzwGxVPdzW72PwJtDrdfLLwPeraq6q/gH4MvALrOJrZDWGfpc/9ZAkwF3A4ar6/aFNB4BdbXkXg7H+k/Xr2+yMbcDLJ/+8Xy2q6uaq2lRVWxhcB1+rql8DHgI+1pqdek5OnquPtfZnVS9uMVX1V8CRJD/bSlcw+GnzXq+T54FtSX66/T908nys3mtkpT9UOEMfzlzN4B9r+R7wn1d6fyZ0zL/I4M/MJ4DH2+1qBuONh4Bn2v15rX0YzHL6HvBtBrMXVvw4zuD5+SXggbb8buCbwAzwP4FzW/1tbX2mbX/3Su/3GToXHwCm27Xyv4B1PV8nwO8B3wW+A3wROHc1XyP+DIMkdWQ1Du9IkuZh6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SO/BNHzPhxKmqzngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(max_len, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping max len of 500 tokens\n",
    "\n",
    "question_titles = [i[:500] for i in question_titles]\n",
    "questions = [i[:500] for i in questions]\n",
    "answers = [i[:500] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1297, 2094, 2748])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some texts are reduced to 0 words after tokenizing (dropping out all non token words)\n",
    "# dropping them\n",
    "\n",
    "to_drop = []\n",
    "\n",
    "qt = []\n",
    "for i in question_titles:\n",
    "    qt.append(len(i))\n",
    "qt = np.array(qt)\n",
    "qt = np.where(qt<1)[0]\n",
    "q = []\n",
    "for i in questions:\n",
    "    q.append(len(i))\n",
    "q = np.array(q)\n",
    "q = np.where(q<1)[0]\n",
    "a = []\n",
    "for i in answers:\n",
    "    a.append(len(i))\n",
    "a = np.array(a)\n",
    "a = np.where(a<1)[0]\n",
    "\n",
    "for i in qt:\n",
    "    to_drop.append(i)\n",
    "for i in q:\n",
    "    to_drop.append(i)\n",
    "for i in a:\n",
    "    to_drop.append(i)\n",
    "    \n",
    "to_drop = np.unique(np.array(to_drop))\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping data with those indices\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['question_titles'] = question_titles\n",
    "df['questions'] = questions\n",
    "df['answers'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index = to_drop)\n",
    "data = data.drop(index=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all to single dataframe and saving\n",
    "data['question_titles'] = df['question_titles']\n",
    "data['questions'] = df['questions']\n",
    "data['answers'] = df['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6076 entries, 0 to 6078\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   question_title                         6076 non-null   object \n",
      " 1   question_body                          6076 non-null   object \n",
      " 2   answer                                 6076 non-null   object \n",
      " 3   question_asker_intent_understanding    6076 non-null   float64\n",
      " 4   question_body_critical                 6076 non-null   float64\n",
      " 5   question_conversational                6076 non-null   float64\n",
      " 6   question_expect_short_answer           6076 non-null   float64\n",
      " 7   question_fact_seeking                  6076 non-null   float64\n",
      " 8   question_has_commonly_accepted_answer  6076 non-null   float64\n",
      " 9   question_interestingness_others        6076 non-null   float64\n",
      " 10  question_interestingness_self          6076 non-null   float64\n",
      " 11  question_multi_intent                  6076 non-null   float64\n",
      " 12  question_not_really_a_question         6076 non-null   float64\n",
      " 13  question_opinion_seeking               6076 non-null   float64\n",
      " 14  question_type_choice                   6076 non-null   float64\n",
      " 15  question_type_compare                  6076 non-null   float64\n",
      " 16  question_type_consequence              6076 non-null   float64\n",
      " 17  question_type_definition               6076 non-null   float64\n",
      " 18  question_type_entity                   6076 non-null   float64\n",
      " 19  question_type_instructions             6076 non-null   float64\n",
      " 20  question_type_procedure                6076 non-null   float64\n",
      " 21  question_type_reason_explanation       6076 non-null   float64\n",
      " 22  question_type_spelling                 6076 non-null   float64\n",
      " 23  question_well_written                  6076 non-null   float64\n",
      " 24  answer_helpful                         6076 non-null   float64\n",
      " 25  answer_level_of_information            6076 non-null   float64\n",
      " 26  answer_plausible                       6076 non-null   float64\n",
      " 27  answer_relevance                       6076 non-null   float64\n",
      " 28  answer_satisfaction                    6076 non-null   float64\n",
      " 29  answer_type_instructions               6076 non-null   float64\n",
      " 30  answer_type_procedure                  6076 non-null   float64\n",
      " 31  answer_type_reason_explanation         6076 non-null   float64\n",
      " 32  answer_well_written                    6076 non-null   float64\n",
      " 33  question_titles                        6076 non-null   object \n",
      " 34  questions                              6076 non-null   object \n",
      " 35  answers                                6076 non-null   object \n",
      "dtypes: float64(30), object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('../datasets/train_processed.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = load_vectors('/home/ksaver/Desktop/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting embeddings for our chosen tokens\n",
    "\n",
    "w2v_embeddings = {}\n",
    "\n",
    "for i in list(tokens.keys()):\n",
    "    embedding = vecs.get(i)\n",
    "    if embedding:\n",
    "        w2v_embeddings[i] = list(embedding)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7227"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8276"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling embeddings\n",
    "import pickle\n",
    "\n",
    "with open('../datasets/w2v_embeddings.pickle', 'wb') as f:\n",
    "    pickle.dump(w2v_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading back embeddings\n",
    "import pickle\n",
    "\n",
    "with open('../datasets/w2v_embeddings.pickle', 'rb') as f:\n",
    "    w2v_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting texts into word2vec embeddings\n",
    "\n",
    "def convert_w2v(inputs):\n",
    "    \n",
    "    padding = []\n",
    "\n",
    "    for i in range(300):\n",
    "        padding.append(0.)\n",
    "\n",
    "    vec = []\n",
    "    vec_final = []\n",
    "\n",
    "    for i in inputs:\n",
    "        embedded = []\n",
    "        words = i.split(' ')\n",
    "        for j in words:\n",
    "            word = w2v_embeddings.get(j)\n",
    "            if word:\n",
    "                embedded.append(word)\n",
    "        vec.append(embedded[:500])\n",
    "        \n",
    "    lens = []\n",
    "\n",
    "    for i in vec:\n",
    "        lens.append(len(i))\n",
    "\n",
    "    max_len = max(lens)\n",
    "    \n",
    "    for i in vec:\n",
    "        embedding = i.copy()\n",
    "        for j in range(max_len-len(i)):\n",
    "            embedding.append(padding)\n",
    "        vec_final.append(np.array(embedding))\n",
    "        \n",
    "    return(np.array(vec_final, dtype = np.float16))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles_vec = convert_w2v(question_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 32, 300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_titles_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_vec = convert_w2v(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 500, 300)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_vec = convert_w2v(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 500, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [1297, 2094, 2748]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles_vec = np.delete(question_titles_vec, to_drop, axis = 0)\n",
    "questions_vec = np.delete(questions_vec, to_drop, axis = 0)\n",
    "answers_vec = np.delete(answers_vec, to_drop, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6076, 32, 300), (6076, 500, 300), (6076, 500, 300))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_titles_vec.shape, questions_vec.shape, answers_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling\n",
    "\n",
    "with open('../datasets/question_titles_vec.pickle', 'wb') as f:\n",
    "    pickle.dump(question_titles_vec, f)\n",
    "    \n",
    "with open('../datasets/questions_vec.pickle', 'wb') as f:\n",
    "    pickle.dump(questions_vec, f)\n",
    "    \n",
    "with open('../datasets/answers_vec.pickle', 'wb') as f:\n",
    "    pickle.dump(answers_vec, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
