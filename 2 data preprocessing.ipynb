{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/train_shortened.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all columns except question title, question, answer and ratings\n",
    "\n",
    "cols = ['question_title', 'question_body', 'answer']\n",
    "for i in data.columns[12:]:\n",
    "    cols.append(i)\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "\n",
    "## Lowercasing and removing special characters\n",
    "\n",
    "All special chars, except .?! are removed to keep clean text data. Stop, quetion mark and exclamation mark are kept, and will gain separate tokens, as end of sentence markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = data['question_title'].values.copy()\n",
    "questions = data['question_body'].values.copy()\n",
    "answers = data['answer'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessor(texts):\n",
    "\n",
    "    # final list\n",
    "    texts_prep = []\n",
    "    # chars to remove from text\n",
    "    filters =['\\'', '\\\"', '$', '%' ,'&', '(', ')', '*', ',', '+', '-', '/',':',';','<','=','>'\n",
    "              ,'[',']','^','_','`','{','|','}','~','\\t','\\n', '@', '\\\\']\n",
    "\n",
    "    # cleaning whitespace: only one (' ') remains\n",
    "    whitespace_cleaner = re.compile(r'\\s+')\n",
    "    for i in range(len(texts)):\n",
    "        texts[i] = whitespace_cleaner.sub(' ', texts[i]).strip()\n",
    "\n",
    "    # for each text\n",
    "    for text in texts:\n",
    "        # split it by whitespace\n",
    "        split = text.split(' ')\n",
    "        # list to save preprocessed text\n",
    "        to_add = []\n",
    "        # going word by word\n",
    "        for word in split:\n",
    "            proc = []\n",
    "            # making list of valid words, removing urls\n",
    "            if word.isascii() and word.startswith('http') == False:\n",
    "                x = list(word)\n",
    "                # going char by char\n",
    "                for i in x:\n",
    "                    # if char is not to be filtered out, keep it, else add whitespace instead of it\n",
    "                    if i not in filters:\n",
    "                        # if .?!, add whitespace to it, to keep it as separate token\n",
    "                        if i == '?' or i == '.' or i == '!':\n",
    "                            proc.append(' ' + i)\n",
    "                        else:\n",
    "                            proc.append(i)\n",
    "                    else:\n",
    "                        proc.append(' ')\n",
    "                    if '' in proc:\n",
    "                        proc.remove('')\n",
    "                # apending word to to_add list, which contains its whole text\n",
    "                to_add.append(''.join(proc).lower())\n",
    "                    \n",
    "        # apending list of words back to all texts list\n",
    "        texts_prep.append(' '.join(to_add).strip())\n",
    "        \n",
    "    # cleaning whitespace again: only one (' ') remains\n",
    "    whitespace_cleaner = re.compile(r'\\s+')\n",
    "    for i in range(len(texts_prep)):\n",
    "        texts_prep[i] = whitespace_cleaner.sub(' ', texts_prep[i]).strip()\n",
    "        \n",
    "    return texts_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = text_preprocessor(question_titles)\n",
    "questions = text_preprocessor(questions)\n",
    "answers = text_preprocessor(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:    I understand the problem with people cheating the first post review audits by simply clicking the add comment button, but there really has to be a more graceful way to handle it.\n",
      "\n",
      "It should be as simple as forcing the person to actually write the comment and submit it which will make it less abusable, and if they are abusing the system, they'll be caught quick because they'll actually be posting their (presumably canned) comments on real questions.\n",
      "\n",
      "and if the comments actually aren't canned and relevant to the question anyway, than it's really not that harmful that people are doing it.\n",
      "\n",
      "Both edit and add comment are neutral actions, and it doesn't make sense for someone to fail an audit regardless of whether the post is good or bad(unless it's a blatant spam post or something)\n",
      " \n",
      " PROCESSED:    i understand the problem with people cheating the first post review audits by simply clicking the add comment button but there really has to be a more graceful way to handle it . it should be as simple as forcing the person to actually write the comment and submit it which will make it less abusable and if they are abusing the system they ll be caught quick because they ll actually be posting their presumably canned comments on real questions . and if the comments actually aren t canned and relevant to the question anyway than it s really not that harmful that people are doing it . both edit and add comment are neutral actions and it doesn t make sense for someone to fail an audit regardless of whether the post is good or bad unless it s a blatant spam post or something \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    While a good color scheme will help, the key thing to note here is the need for contrast for enhanced readability. To quote this article from eyemagzine \n",
      "\n",
      "\n",
      "  Light grey text on a white background and small text size both lead to\n",
      "  an increased orbicularis oculi activity and decreased blinking. These\n",
      "  two conditions are related to text quality, and we would expect to\n",
      "  find similar indicators of eye fatigue with poor font quality or\n",
      "  condensed letter spacing.\n",
      "\n",
      "\n",
      "For examples of good color combinations with sufficient contrast I recommend reading this article on UX matters which has this to say on what contrast to choose for minimal eye strain.\n",
      "\n",
      "\n",
      "  Ensuring the Readability of Text Through Contrast\n",
      "  \n",
      "  For backgrounds behind text, use solid, contrasting colors, and avoid\n",
      "  the use of textures and patterns, which can make letterforms difficult\n",
      "  to distinguish or even illegible. Choose combinations of text color\n",
      "  and background color with care. Value contrast between body text and\n",
      "  its background color should be a minimum of about eighty percent.\n",
      "  \n",
      "  Contrast with a white background\n",
      "  \n",
      "  Black text on a white background provides maximal value contrast and,\n",
      "  therefore, optimal readability for body text. The contrast between\n",
      "  charcoal gray (#333333) text and a white background is about eighty\n",
      "  percent—thus giving minimally good value contrast. - \n",
      "  \n",
      "  The following dark colors provide good to excellent contrast and\n",
      "  legibility for text on a white background: \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      "The importance of contrast with regards to reducing eye strain is explained further in the article as highlighted below\n",
      "\n",
      "\n",
      "  Contrast and Legibility “To provide the best legibility, ensure that text contrasts adequately with its background in both hue and\n",
      "  value.”\n",
      "  \n",
      "  To provide the best legibility, ensure that text contrasts adequately\n",
      "  with its background in both hue and value. When there is insufficient\n",
      "  contrast between the hue or value of text and its background color,\n",
      "  the text appears blurred or has a halo effect around it, making it\n",
      "  difficult to read and resulting in eye strain.\n",
      "\n",
      "\n",
      "That said the choice of text and size is also critical. To quote the above referenced eye magazine site article\n",
      "\n",
      "\n",
      "  Designers usually try to use high quality text when readers are\n",
      "  expected to read for any period of time, but using a comfortable text\n",
      "  size is not always possible. In print, there is a trade-off between\n",
      "  type size and the amount of text that can fit on a page. Nine-point\n",
      "  type may be chosen because it is cost-effective, whereas eleven-point\n",
      "  would be easier to identify visually and would reduce eye strain.\n",
      "  Twelve-point text may be needed for good character definition on\n",
      "  computer screens, because readers frequently sit further from a screen\n",
      "  than from a printed page, but many Web pages specify small font sizes\n",
      "  despite the fact that it \n",
      " PROCESSED:    while a good color scheme will help the key thing to note here is the need for contrast for enhanced readability . to quote this article from eyemagzine light grey text on a white background and small text size both lead to an increased orbicularis oculi activity and decreased blinking . these two conditions are related to text quality and we would expect to find similar indicators of eye fatigue with poor font quality or condensed letter spacing . for examples of good color combinations with sufficient contrast i recommend reading this article on ux matters which has this to say on what contrast to choose for minimal eye strain . ensuring the readability of text through contrast for backgrounds behind text use solid contrasting colors and avoid the use of textures and patterns which can make letterforms difficult to distinguish or even illegible . choose combinations of text color and background color with care . value contrast between body text and its background color should be a minimum of about eighty percent . contrast with a white background black text on a white background provides maximal value contrast and therefore optimal readability for body text . the contrast between charcoal gray #333333 text and a white background is about eighty giving minimally good value contrast . the following dark colors provide good to excellent contrast and legibility for text on a white background the importance of contrast with regards to reducing eye strain is explained further in the article as highlighted below contrast and legibility provide the best legibility ensure that text contrasts adequately with its background in both hue and to provide the best legibility ensure that text contrasts adequately with its background in both hue and value . when there is insufficient contrast between the hue or value of text and its background color the text appears blurred or has a halo effect around it making it difficult to read and resulting in eye strain . that said the choice of text and size is also critical . to quote the above referenced eye magazine site article designers usually try to use high quality text when readers are expected to read for any period of time but using a comfortable text size is not always possible . in print there is a trade off between type size and the amount of text that can fit on a page . nine point type may be chosen because it is cost effective whereas eleven point would be easier to identify visually and would reduce eye strain . twelve point text may be needed for good character definition on computer screens because readers frequently sit further from a screen than from a printed page but many web pages specify small font sizes despite the fact that it \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    \n",
      "  Some people say since \"so\" is a transitional word…\n",
      "\n",
      "\n",
      "There aren't traditional words, there are traditional senses. Compare:\n",
      "\n",
      "\n",
      "  Mix all of these ingredients together. Next, add the milk.\n",
      "  \n",
      "  I love Firefly. Next to Twin Peaks it is my favourite programme.\n",
      "\n",
      "\n",
      "I've deliberately picked a different \"transitional word\" to hopefully make it easier to see the point if you're perhaps over-thinking so.\n",
      "\n",
      "In the first case here, next is indeed in a transitional sense—it serves to introduce the next sentence while also stating they are in a temporal order—and the comma makes sense.\n",
      "\n",
      "In the second case next is not doing this transitional job, but telling us something about how the topic of discussion (Firefly) relates to another thing (Twin Peaks) in the writer's opinion. We don't want to separate it from the to; what would the now separated \"to Twin Peaks it is…\" even mean?\n",
      "\n",
      "So, back to so.\n",
      "\n",
      "So's transitional sense is \"used after a pause for thought to introduce a new topic, question or story.\" In this sense you can remove it and not really lose much meaning, though might you lose impact. If you want your sentence to mean \"I am confident that …\" but with so serving this introductory role, then the comma might be a good idea for that reason. (It might also be a good idea to just cut it, but that's another matter).\n",
      "\n",
      "Another sense of so is \"therefore\" or \"with the result that\". If you want so to say that the studies you mention in the previous sentence (along, perhaps, with earlier statements) is the reason why you have this confidence, then the comma is probably a bad idea.\n",
      "\n",
      "I imagine you want the second of these two readings, and I'd therefore recommend that you don't use a comma.\n",
      " \n",
      " PROCESSED:    some people say since so is a transitional there aren t traditional words there are traditional senses . compare mix all of these ingredients together . next add the milk . i love firefly . next to twin peaks it is my favourite programme . i ve deliberately picked a different transitional word to hopefully make it easier to see the point if you re perhaps over thinking so . in the first case here next is indeed in a transitional serves to introduce the next sentence while also stating they are in a temporal the comma makes sense . in the second case next is not doing this transitional job but telling us something about how the topic of discussion firefly relates to another thing twin peaks in the writer s opinion . we don t want to separate it from the to what would the now separated to twin peaks it even mean ? so back to so . so s transitional sense is used after a pause for thought to introduce a new topic question or story . in this sense you can remove it and not really lose much meaning though might you lose impact . if you want your sentence to mean i am confident that but with so serving this introductory role then the comma might be a good idea for that reason . it might also be a good idea to just cut it but that s another matter . another sense of so is therefore or with the result that . if you want so to say that the studies you mention in the previous sentence along perhaps with earlier statements is the reason why you have this confidence then the comma is probably a bad idea . i imagine you want the second of these two readings and i d therefore recommend that you don t use a comma . \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    I'm comparing the datasheets for ST Microelectronics' versions of these:\n",
      "\n",
      "\n",
      "L78S12CV\n",
      "L7812CV\n",
      "\n",
      "\n",
      "The performance characteristics, such as Output voltage vs. junction temperature, is identical for both.\n",
      "\n",
      "The operating (junction) temperature is different, 7812 is 0-125°C; 78S12 is 0-150°C.\n",
      "\n",
      "In both cases, in a TO-220 package, the thermal resistance is the same: 5°C/W for junction-case, and 50°C/W for junction-ambient.\n",
      "\n",
      "Based on this information, I would not expect the 78S12 to run cooler given the same load and heatsink. But it can handle higher operating temperatures, which may be a reason to favor it.\n",
      " \n",
      " PROCESSED:    i m comparing the datasheets for st microelectronics versions of these l78s12cv l7812cv the performance characteristics such as output voltage vs . junction temperature is identical for both . the operating junction temperature is different 7812 is 78s12 is in both cases in a to 220 package the thermal resistance is the same for junction case and for junction ambient . based on this information i would not expect the 78s12 to run cooler given the same load and heatsink . but it can handle higher operating temperatures which may be a reason to favor it . \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    The Guava Framework supports such called Mutlimaps oder Multisets. Check this out: https://code.google.com/p/guava-libraries/wiki/NewCollectionTypesExplained\n",
      " \n",
      " PROCESSED:    the guava framework supports such called mutlimaps oder multisets . check this out \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing few answers before and after preprocessing\n",
    "\n",
    "rdm = np.random.randint(0,len(answers), 5)\n",
    "\n",
    "for i in rdm:\n",
    "    print('ORIGINAL:   ', data.iloc[i]['answer'], '\\n', 'PROCESSED:   ', answers[i], '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging all words in tweets, and keeping tags only for nouns, verbs, adjectives and adverbs\n",
    "\n",
    "def pos_tagger(texts):\n",
    "\n",
    "    # procesed array-to-be\n",
    "    texts_tagged = []\n",
    "\n",
    "    for text in texts:\n",
    "        # here each text is added after tagging\n",
    "        tagged_final = []\n",
    "        # splitting by whitespace and tagging\n",
    "        split = text.split(' ')\n",
    "        split = np.array(split)\n",
    "        # some '' are stil left in list, cleaning them with numpy where\n",
    "        where = np.where(split == '')\n",
    "        split = np.delete(split, where)\n",
    "        tagged = nltk.pos_tag(split)\n",
    "        # keeping only tags for nouns, verbs, adjectives and adverbs\n",
    "        for item in tagged:\n",
    "            if item[1].startswith('N'):\n",
    "                tagged_final.append((item[0],'n'))\n",
    "            elif item[1].startswith('V'):\n",
    "                tagged_final.append((item[0],'v'))\n",
    "            elif item[1].startswith('J'):\n",
    "                tagged_final.append((item[0],'a'))\n",
    "            elif item[1].startswith('R'):\n",
    "                tagged_final.append((item[0],'r'))\n",
    "            else:\n",
    "                tagged_final.append((item[0], None))\n",
    "        # adding back to final list\n",
    "        texts_tagged.append(tagged_final)\n",
    "    \n",
    "    return np.array(texts_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = pos_tagger(question_titles)\n",
    "questions = pos_tagger(questions)\n",
    "answers = pos_tagger(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', None),\n",
       " ('am', 'v'),\n",
       " ('i', 'a'),\n",
       " ('losing', 'n'),\n",
       " ('when', None),\n",
       " ('using', 'v'),\n",
       " ('extension', 'n'),\n",
       " ('tubes', 'n'),\n",
       " ('instead', 'r'),\n",
       " ('of', None),\n",
       " ('a', None),\n",
       " ('macro', 'n'),\n",
       " ('lens', 'n'),\n",
       " ('?', None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(texts):\n",
    "    \n",
    "    # using wordnet lemmatizer\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lem = WordNetLemmatizer()\n",
    "    \n",
    "    # lemmatized texts list to be\n",
    "    texts_lemmed = []\n",
    "    # going text by text, if word has valid tag (not None), lemmatize it\n",
    "    for text in texts:\n",
    "        to_add = []\n",
    "        for i,j in text:\n",
    "            if j == None:\n",
    "                to_add.append(i)\n",
    "            else:\n",
    "                to_add.append(lem.lemmatize(i, pos = j))\n",
    "        texts_lemmed.append(' '.join(to_add))\n",
    "    \n",
    "    return np.array(texts_lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = lemmatize(question_titles)\n",
    "questions = lemmatize(questions)\n",
    "answers = lemmatize(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['what be i losing when use extension tube instead of a macro lens ?',\n",
       "       'what be the distinction between a city and a sprawl metroplex . . . between downtown and a commercial district ?',\n",
       "       'maximum protusion length for through hole component pin', ...,\n",
       "       'suppress file truncate message when use tail',\n",
       "       'when should a supervisor be a co author ?',\n",
       "       'why be there so many different type of screw phillps flat hex star etc ?'],\n",
       "      dtype='<U140')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking all texts together\n",
    "\n",
    "all_texts = np.hstack((question_titles, questions, answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1741106"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing how many unique words there are\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for i in all_texts:\n",
    "    x = i.split(' ')\n",
    "    for j in x:\n",
    "        all_words.append(j)\n",
    "        \n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44123"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique words\n",
    "\n",
    "len(list(set(all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44123"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only words which show up 10 or more times in tweets as tokens, discarding rest\n",
    "\n",
    "tokens = {k:v for k,v in freq_dist.items() if v >= 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8276"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting tokenizer on all texts\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tok = Tokenizer(num_words = 8277, filters = '')\n",
    "\n",
    "tok.fit_on_texts(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_titles = tok.texts_to_sequences(question_titles)\n",
    "questions = tok.texts_to_sequences(questions)\n",
    "answers = tok.texts_to_sequences(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max len\n",
    "\n",
    "max_len = []\n",
    "\n",
    "for i in question_titles:\n",
    "    max_len.append(len(i))\n",
    "for i in questions:\n",
    "    max_len.append(len(i))\n",
    "for i in answers:\n",
    "    max_len.append(len(i))\n",
    "    \n",
    "max(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18237.000000\n",
       "mean        90.573340\n",
       "std        107.365434\n",
       "min          0.000000\n",
       "5%           5.000000\n",
       "25%         12.000000\n",
       "50%         55.000000\n",
       "75%        126.000000\n",
       "95%        310.000000\n",
       "99%        512.000000\n",
       "max        887.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(max_len).describe(percentiles=[0.05,0.25,0.5,0.75,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(max_len, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping max len of 500 tokens\n",
    "\n",
    "question_titles = [i[:500] for i in question_titles]\n",
    "questions = [i[:500] for i in questions]\n",
    "answers = [i[:500] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1297, 2094, 2748])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some texts are reduced to 0 words after tokenizing (dropping out all non token words)\n",
    "# dropping them\n",
    "\n",
    "to_drop = []\n",
    "\n",
    "qt = []\n",
    "for i in question_titles:\n",
    "    qt.append(len(i))\n",
    "qt = np.array(qt)\n",
    "qt = np.where(qt<1)[0]\n",
    "q = []\n",
    "for i in questions:\n",
    "    q.append(len(i))\n",
    "q = np.array(q)\n",
    "q = np.where(q<1)[0]\n",
    "a = []\n",
    "for i in answers:\n",
    "    a.append(len(i))\n",
    "a = np.array(a)\n",
    "a = np.where(a<1)[0]\n",
    "\n",
    "for i in qt:\n",
    "    to_drop.append(i)\n",
    "for i in q:\n",
    "    to_drop.append(i)\n",
    "for i in a:\n",
    "    to_drop.append(i)\n",
    "    \n",
    "to_drop = np.unique(np.array(to_drop))\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping data with those indices\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['question_titles'] = question_titles\n",
    "df['questions'] = questions\n",
    "df['answers'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index = to_drop)\n",
    "data = data.drop(index=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all to single dataframe and saving\n",
    "data['question_titles'] = df['question_titles']\n",
    "data['questions'] = df['questions']\n",
    "data['answers'] = df['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6076 entries, 0 to 6078\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   question_title                         6076 non-null   object \n",
      " 1   question_body                          6076 non-null   object \n",
      " 2   answer                                 6076 non-null   object \n",
      " 3   question_asker_intent_understanding    6076 non-null   float64\n",
      " 4   question_body_critical                 6076 non-null   float64\n",
      " 5   question_conversational                6076 non-null   float64\n",
      " 6   question_expect_short_answer           6076 non-null   float64\n",
      " 7   question_fact_seeking                  6076 non-null   float64\n",
      " 8   question_has_commonly_accepted_answer  6076 non-null   float64\n",
      " 9   question_interestingness_others        6076 non-null   float64\n",
      " 10  question_interestingness_self          6076 non-null   float64\n",
      " 11  question_multi_intent                  6076 non-null   float64\n",
      " 12  question_not_really_a_question         6076 non-null   float64\n",
      " 13  question_opinion_seeking               6076 non-null   float64\n",
      " 14  question_type_choice                   6076 non-null   float64\n",
      " 15  question_type_compare                  6076 non-null   float64\n",
      " 16  question_type_consequence              6076 non-null   float64\n",
      " 17  question_type_definition               6076 non-null   float64\n",
      " 18  question_type_entity                   6076 non-null   float64\n",
      " 19  question_type_instructions             6076 non-null   float64\n",
      " 20  question_type_procedure                6076 non-null   float64\n",
      " 21  question_type_reason_explanation       6076 non-null   float64\n",
      " 22  question_type_spelling                 6076 non-null   float64\n",
      " 23  question_well_written                  6076 non-null   float64\n",
      " 24  answer_helpful                         6076 non-null   float64\n",
      " 25  answer_level_of_information            6076 non-null   float64\n",
      " 26  answer_plausible                       6076 non-null   float64\n",
      " 27  answer_relevance                       6076 non-null   float64\n",
      " 28  answer_satisfaction                    6076 non-null   float64\n",
      " 29  answer_type_instructions               6076 non-null   float64\n",
      " 30  answer_type_procedure                  6076 non-null   float64\n",
      " 31  answer_type_reason_explanation         6076 non-null   float64\n",
      " 32  answer_well_written                    6076 non-null   float64\n",
      " 33  question_titles                        6076 non-null   object \n",
      " 34  questions                              6076 non-null   object \n",
      " 35  answers                                6076 non-null   object \n",
      "dtypes: float64(30), object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('../datasets/train_processed.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
